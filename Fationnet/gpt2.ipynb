{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e61a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 3 cars, 38.2ms\n",
      "Speed: 2.1ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 car, 37.3ms\n",
      "Speed: 1.8ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Person 3 features (Upper+Lower): [   0.075738     0.21523    0.028669    0.011125   0.0017116   0.0008558           0           0           0           0]\n",
      "Person 4 Texture - Contrast: 123.13685636856368, Energy: 0.03933042079593494, Homogeneity: 0.1721183819388773\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'out_dir' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 187\u001b[0m\n\u001b[0;32m    184\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mimwrite(out_path, vis)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     process_all()\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete. Segmented images saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUTPUT_DIR)\n",
      "Cell \u001b[1;32mIn[4], line 173\u001b[0m, in \u001b[0;36mprocess_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mcircle(vis, coords[key], \u001b[38;5;241m5\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# hand points\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Show and save histograms for upper, lower, and hands\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m hist_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistograms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(hist_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m plot_histogram(crop, upper, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Upper HSV Histogram\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hist_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_p\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_upper_hist.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'out_dir' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths - adjust to your local setup\n",
    "INPUT_DIR = 'Time_12-34'              # folder containing JPEG frames\n",
    "OUTPUT_DIR = 'output_segmentsa'      # folder where results will be saved\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Device for PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load YOLOv8n for person detection\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Load DeepLabV3 (ResNet-50 backbone) for semantic segmentation\n",
    "def load_segmentation_model():\n",
    "    model = deeplabv3_resnet50(pretrained=True, progress=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "segmentation_model = load_segmentation_model()\n",
    "\n",
    "# Preprocessing transform for DeepLabV3\n",
    "seg_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((520, 520)),   # model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize MediaPipe Pose for body-part splitting\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=True)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Helper: get segmentation mask via ResNet50 backbone\n",
    "def get_person_mask_resnet(crop):\n",
    "    img = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "    inp = seg_transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = segmentation_model(inp)['out'][0]  # [C, H, W]\n",
    "        person_logits = out[15]\n",
    "        person_prob = torch.sigmoid(person_logits)\n",
    "        mask = person_prob.cpu().numpy() > 0.5\n",
    "    mask = cv2.resize(mask.astype(np.uint8), (crop.shape[1], crop.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    return mask.astype(bool)\n",
    "\n",
    "# Helper: get pose landmarks\n",
    "def get_landmarks(crop):\n",
    "    rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "    res = mp_pose.process(rgb)\n",
    "    return res.pose_landmarks\n",
    "\n",
    "# Helper: split mask into upper, lower, hands\n",
    "def split_parts(mask, landmarks):\n",
    "    H, W = mask.shape\n",
    "    coords = {}\n",
    "    for idx, lm in enumerate(landmarks.landmark):\n",
    "        name = mp.solutions.pose.PoseLandmark(idx).name\n",
    "        coords[name] = (int(lm.x * W), int(lm.y * H))\n",
    "\n",
    "    hip_y = int((coords['LEFT_HIP'][1] + coords['RIGHT_HIP'][1]) / 2)\n",
    "    fg = mask\n",
    "    rows = np.arange(H)[:, None]\n",
    "    upper = fg & (rows < hip_y)\n",
    "    lower = fg & (rows >= hip_y)\n",
    "\n",
    "    hands = np.zeros_like(fg, dtype=bool)\n",
    "    r = int(0.1 * H)\n",
    "    for side in ['LEFT', 'RIGHT']:\n",
    "        key = f'{side}_WRIST'\n",
    "        if key in coords:\n",
    "            wx, wy = coords[key]\n",
    "            y0, y1 = max(0, wy-r), min(H, wy+r)\n",
    "            x0, x1 = max(0, wx-r), min(W, wx+r)\n",
    "            hands[y0:y1, x0:x1] = True\n",
    "\n",
    "    return upper, lower, hands, coords\n",
    "\n",
    "# Plot HSV histogram\n",
    "def plot_histogram(region_img, mask, title, save_path=None):\n",
    "    hsv = cv2.cvtColor(region_img, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0], mask.astype(np.uint8), [180], [0, 180])\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Hue\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.plot(hist, color='orange')\n",
    "    plt.xlim([0, 180])\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# Feature extractor for color + texture\n",
    "def extract_clothing_features(region_img, region_mask):\n",
    "    region = cv2.bitwise_and(region_img, region_img, mask=region_mask.astype(np.uint8))\n",
    "    hsv = cv2.cvtColor(region, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], region_mask.astype(np.uint8), [16], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], region_mask.astype(np.uint8), [16], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], region_mask.astype(np.uint8), [16], [0, 256])\n",
    "    color_hist = np.concatenate([hist_h, hist_s, hist_v]).flatten()\n",
    "    color_hist = color_hist / (np.sum(color_hist) + 1e-6)\n",
    "\n",
    "    gray = rgb2gray(region)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp[region_mask], bins=10, range=(0, 10), density=True)\n",
    "\n",
    "    return np.concatenate([color_hist, lbp_hist])\n",
    "\n",
    "# Texture features from grayscale image\n",
    "def get_texture_features(gray_img):\n",
    "    glcm = graycomatrix((gray_img * 255).astype(np.uint8), distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    return contrast, energy, homogeneity\n",
    "\n",
    "# Process all JPEG frames\n",
    "def process_all():\n",
    "    imgs = glob.glob(os.path.join(INPUT_DIR, '**', '*.jpg'), recursive=True)\n",
    "    for img_path in imgs:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        results = yolo_model(img)[0]\n",
    "        person_boxes = [box.xyxy[0].cpu().numpy().astype(int)\n",
    "                        for box, cls in zip(results.boxes, results.boxes.cls)\n",
    "                        if int(cls) == 0]\n",
    "\n",
    "        for i, (x1, y1, x2, y2) in enumerate(person_boxes):\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            mask = get_person_mask_resnet(crop)\n",
    "            landmarks = get_landmarks(crop)\n",
    "            if not landmarks:\n",
    "                continue\n",
    "            upper, lower, hands, coords = split_parts(mask, landmarks)\n",
    "\n",
    "            # Feature extraction for clothing\n",
    "            upper_feat = extract_clothing_features(crop, upper)\n",
    "            lower_feat = extract_clothing_features(crop, lower)\n",
    "            person_id_vector = np.concatenate([upper_feat, lower_feat])\n",
    "            print(f\"Person {i} features (Upper+Lower):\", person_id_vector[:10])\n",
    "\n",
    "            # Additional grayscale texture features\n",
    "            gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "            contrast, energy, homogeneity = get_texture_features(gray_crop)\n",
    "            print(f\"Person {i + 1} Texture - Contrast: {contrast}, Energy: {energy}, Homogeneity: {homogeneity}\")\n",
    "\n",
    "            # Draw lines for body parts\n",
    "            vis = crop.copy()\n",
    "            if 'LEFT_SHOULDER' in coords and 'RIGHT_SHOULDER' in coords:\n",
    "                cv2.line(vis, coords['LEFT_SHOULDER'], coords['RIGHT_SHOULDER'], (0, 0, 255), 2)  # upper body line\n",
    "            if 'LEFT_HIP' in coords and 'RIGHT_HIP' in coords:\n",
    "                cv2.line(vis, coords['LEFT_HIP'], coords['RIGHT_HIP'], (0, 255, 0), 2)  # lower body line\n",
    "            for side in ['LEFT', 'RIGHT']:\n",
    "                key = f'{side}_WRIST'\n",
    "                if key in coords:\n",
    "                    cv2.circle(vis, coords[key], 5, (255, 0, 0), -1)  # hand points\n",
    "\n",
    "            # Show and save histograms for upper, lower, and hands\n",
    "            hist_dir = os.path.join(out_dir, \"histograms\")\n",
    "            os.makedirs(hist_dir, exist_ok=True)\n",
    "            plot_histogram(crop, upper, f\"Person {i+1} Upper HSV Histogram\", os.path.join(hist_dir, f\"{basename}_p{i}_upper_hist.png\"))\n",
    "            plot_histogram(crop, lower, f\"Person {i+1} Lower HSV Histogram\", os.path.join(hist_dir, f\"{basename}_p{i}_lower_hist.png\"))\n",
    "            plot_histogram(crop, hands, f\"Person {i+1} Hand HSV Histogram\", os.path.join(hist_dir, f\"{basename}_p{i}_hand_hist.png\"))\n",
    "\n",
    "            rel_dir = os.path.relpath(os.path.dirname(img_path), INPUT_DIR)\n",
    "            out_dir = os.path.join(OUTPUT_DIR, rel_dir)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            out_path = os.path.join(out_dir, f\"{basename}_p{i}.jpg\")\n",
    "            cv2.imwrite(out_path, vis)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_all()\n",
    "    print(\"Processing complete. Segmented images saved to:\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
